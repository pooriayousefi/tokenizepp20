# Tokenize++20 - Modern String Tokenization

[![Build Status](https://github.com/pooriayousefi/tokenizepp20/actions/workflows/ci.yml/badge.svg)](https://github.com/pooriayousefi/tokenizepp20/actions/workflows/ci.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![C++20](https://img.shields.io/badge/C%2B%2B-20-blue.svg)](https://en.wikipedia.org/wiki/C%2B%2B20)
[![CMake](https://img.shields.io/badge/CMake-3.20%2B-green.svg)](https://cmake.org/)

A modern C++20 header-only library providing conceptual tokenization functions with comprehensive Unicode support. Tokenize++20 offers efficient string parsing with multiple container output options and type-safe interfaces.

## üöÄ Features

- **Header-Only**: Single header include for easy integration
- **C++20 Concepts**: Type-safe string concept constraints
- **Unicode Support**: Full support for std::string, std::wstring, std::u16string, std::u32string
- **Multiple Containers**: Output to vector, unordered_set, or unordered_map
- **High Performance**: Optimized parsing algorithms with minimal allocations
- **Cross-Platform**: Works on Linux (g++), macOS (clang++), and Windows (MSVC)

## üéØ Quick Start

```cpp
#include "tokenizepp20.h"
#include <iostream>
#include <vector>
#include <unordered_set>
#include <unordered_map>

int main() {
    const std::string text = "Hello, world! How are you today?";
    const std::string delimiters = " ,.!?";
    
    // Tokenize to vector (preserves order, allows duplicates)
    std::vector<std::string> tokens_vector;
    tokenize(text, delimiters, tokens_vector);
    
    std::cout << "Vector tokens: ";
    for (const auto& token : tokens_vector) {
        std::cout << token << " ";
    }
    std::cout << std::endl;
    
    // Tokenize to unordered_set (unique tokens only)
    std::unordered_set<std::string> tokens_set;
    tokenize(text, delimiters, tokens_set);
    
    std::cout << "Set tokens: ";
    for (const auto& token : tokens_set) {
        std::cout << token << " ";
    }
    std::cout << std::endl;
    
    // Tokenize to unordered_map (token frequency counting)
    std::unordered_map<std::string, size_t> tokens_map;
    tokenize(text, delimiters, tokens_map);
    
    std::cout << "Map tokens (frequency): ";
    for (const auto& [token, count] : tokens_map) {
        std::cout << token << "(" << count << ") ";
    }
    std::cout << std::endl;
    
    return 0;
}
```

## üìö API Reference

### Core Tokenization Functions

#### Vector Output (Ordered, Duplicates Allowed)

```cpp
template<string T>
auto tokenize(const T& str, const T& delimiters, std::vector<T>& tokens) -> void
```

Tokenizes input string and stores results in a vector, preserving order and allowing duplicate tokens.

#### Set Output (Unique Tokens)

```cpp
template<string T>
auto tokenize(const T& str, const T& delimiters, std::unordered_set<T>& tokens) -> void
```

Tokenizes input string and stores unique tokens in an unordered_set.

#### Map Output (Frequency Counting)

```cpp
template<string T>
auto tokenize(const T& str, const T& delimiters, std::unordered_map<T, size_t>& tokens) -> void
```

Tokenizes input string and stores tokens with their frequency counts in an unordered_map.

### String Concept

The library uses C++20 concepts to ensure type safety:

```cpp
template<typename T>
concept string = std::is_same_v<T, std::string> ||
                std::is_same_v<T, std::wstring> ||
                std::is_same_v<T, std::u16string> ||
                std::is_same_v<T, std::u32string>;
```

## üåê Unicode Support

Full support for different string encodings:

```cpp
// Standard ASCII/UTF-8
std::string text = "Hello, world!";
std::string delims = " ,!";
std::vector<std::string> tokens;
tokenize(text, delims, tokens);

// Wide character (UTF-16/32)
std::wstring wtext = L"H√©llo, w√∏rld!";
std::wstring wdelims = L" ,!";
std::vector<std::wstring> wtokens;
tokenize(wtext, wdelims, wtokens);

// UTF-16
std::u16string u16text = u"Hello, world!";
std::u16string u16delims = u" ,!";
std::vector<std::u16string> u16tokens;
tokenize(u16text, u16delims, u16tokens);

// UTF-32
std::u32string u32text = U"Hello, world!";
std::u32string u32delims = U" ,!";
std::vector<std::u32string> u32tokens;
tokenize(u32text, u32delims, u32tokens);
```

## üîß Advanced Usage

### Complex Delimiter Sets

```cpp
const std::string text = "word1,word2;word3:word4\tword5\nword6";
const std::string delimiters = ",;:\t\n ";  // Multiple delimiters
std::vector<std::string> tokens;
tokenize(text, delimiters, tokens);
```

### Frequency Analysis

```cpp
const std::string document = "the quick brown fox jumps over the lazy dog the fox";
const std::string delimiters = " ";
std::unordered_map<std::string, size_t> word_freq;
tokenize(document, delimiters, word_freq);

// Print word frequencies
for (const auto& [word, count] : word_freq) {
    std::cout << word << ": " << count << " times" << std::endl;
}
```

### Unique Word Extraction

```cpp
const std::string text = "apple banana apple cherry banana date";
const std::string delimiters = " ";
std::unordered_set<std::string> unique_words;
tokenize(text, delimiters, unique_words);

std::cout << "Unique words: " << unique_words.size() << std::endl;
```

## üèóÔ∏è Building from Source

```bash
# Clone repository
git clone https://github.com/pooriayousefi/tokenizepp20.git
cd tokenizepp20

# Build with CMake
cmake --preset=default
cmake --build build/default

# Run tests
./build/default/tokenizepp20_test
```

## üìä Use Cases

- **Text Processing**: Document parsing and analysis
- **Natural Language Processing**: Word extraction and frequency analysis
- **Configuration Files**: Parsing delimited configuration data
- **CSV/TSV Processing**: Structured data parsing
- **Log Analysis**: Log file parsing and filtering
- **Lexical Analysis**: Building tokenizers for domain-specific languages

## üîß Requirements

- C++20 compatible compiler (GCC 11+, Clang 13+, MSVC 2022+)
- CMake 3.20 or later
- Standard library with concepts support

## üìà Performance Characteristics

- **Time Complexity**: O(n) where n is the input string length
- **Space Complexity**: O(m) where m is the number of tokens
- **Memory Efficient**: Single-pass algorithm with minimal temporary allocations

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE.txt](LICENSE.txt) file for details.

---

**Author**: [Pooria Yousefi](https://github.com/pooriayousefi)  
**Repository**: [https://github.com/pooriayousefi/tokenizepp20](https://github.com/pooriayousefi/tokenizepp20)
